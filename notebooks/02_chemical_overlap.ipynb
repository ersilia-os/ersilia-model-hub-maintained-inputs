{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaaf0fff",
   "metadata": {},
   "source": [
    "# Overlap between chemical libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840779eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolToInchiKey\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcNumRings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d59948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi = PandasTools.LoadSDF('chebi.sdf')\n",
    "Antibacterial = PandasTools.LoadSDF('Antibacterial-Library-13880.sdf')\n",
    "drugRepurposing_hub = pd.read_csv('drug_repurposing_hub.csv')\n",
    "drugbank_smiles = pd.read_csv('drugbank_smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c483f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl = pd.read_csv('/home/marina/Documents/DB/reference_cs/chembl_bitbirch_representatives_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e56582",
   "metadata": {},
   "outputs": [],
   "source": [
    "Antibacterial.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec884467",
   "metadata": {},
   "source": [
    "Molecule columns:\n",
    "* chebi['INHIKEY']\n",
    "* Antibacterial['InChI Key']\n",
    "* drugRepurposing_hub['smiles']\n",
    "*  drugbank_smiles['Smiles']\n",
    "* chembl['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e843a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## ðŸ”¢ Molecule Counts in Each Dataset\")\n",
    "print(f\"| {'Dataset':<30} | {'Number of Molecules':<20} |\")\n",
    "print(f\"|{'-'*31}|{'-'*22}|\")\n",
    "print(f\"| {'ChEBI':<30} | {len(chebi):<20} |\")\n",
    "print(f\"| {'Antibacterial Library':<30} | {len(Antibacterial):<20} |\")\n",
    "print(f\"| {'Drug Repurposing Hub':<30} | {len(drugRepurposing_hub):<20} |\")\n",
    "print(f\"| {'DrugBank SMILES':<30} | {len(drugbank_smiles):<20} |\")\n",
    "print(f\"| {'Filtered ChEMBL':<30} | {len(chembl):<20} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd69565",
   "metadata": {},
   "source": [
    "## Add Inchikeys to missing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdinchi import MolToInchiKey\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdinchi import MolToInchiKey\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "import pandas as pd\n",
    "\n",
    "# --- Initialize RDKit Standardizers ---\n",
    "# These are heavy objects, so we create them once globally\n",
    "lfc = rdMolStandardize.LargestFragmentChooser()\n",
    "normalizer = rdMolStandardize.Normalizer()\n",
    "uncharger = rdMolStandardize.Uncharger()\n",
    "\n",
    "def standardize_and_get_inchikey(mol, strip_stereo=True):\n",
    "    \"\"\"\n",
    "    Standardize a molecule:\n",
    "      - Largest fragment (strips salts/solvents)\n",
    "      - Normalize & Uncharge\n",
    "      - Optional stereochemistry stripping\n",
    "    Returns (mol_clean, inchikey, smiles)\n",
    "    \"\"\"\n",
    "    if mol is None:\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        # 1. Largest fragment (remove salts/solvents)\n",
    "        mol = lfc.choose(mol)\n",
    "\n",
    "        # 2. Cleanup + normalize + uncharge\n",
    "        mol = rdMolStandardize.Cleanup(mol)\n",
    "        mol = normalizer.normalize(mol)\n",
    "        mol = uncharger.uncharge(mol)\n",
    "\n",
    "        # 3. Sanitize structure\n",
    "        Chem.SanitizeMol(mol)\n",
    "\n",
    "        # 4. Optionally collapse stereochemistry\n",
    "        if strip_stereo:\n",
    "            Chem.RemoveStereochemistry(mol)\n",
    "\n",
    "        # 5. Generate InChIKey and Canonical SMILES\n",
    "        ik = MolToInchiKey(mol)\n",
    "        smiles = Chem.MolToSmiles(mol, canonical=True, isomericSmiles=not strip_stereo)\n",
    "        \n",
    "        return mol, ik, smiles\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "def process_dataframe_chemistry(df, smiles_col, new_inchikey_col, strip_stereo=True):\n",
    "    \"\"\"\n",
    "    Helper to apply standardization to a specific dataframe.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {smiles_col}...\")\n",
    "    \n",
    "    # Create initial Mol objects\n",
    "    df['Mol_Temp'] = df[smiles_col].apply(lambda x: Chem.MolFromSmiles(str(x)) if pd.notna(x) else None)\n",
    "    \n",
    "    # Apply the standardization function\n",
    "    # This returns a Series of tuples, which we expand into 3 columns\n",
    "    results = df['Mol_Temp'].apply(lambda m: standardize_and_get_inchikey(m, strip_stereo=strip_stereo))\n",
    "    \n",
    "    # Assign results back to dataframe\n",
    "    _, df[new_inchikey_col], df['Canonical_SMILES'] = zip(*results)\n",
    "    \n",
    "    # Cleanup\n",
    "    df.drop('Mol_Temp', axis=1, inplace=True)\n",
    "    \n",
    "    valid_count = df[new_inchikey_col].count()\n",
    "    print(f\"Standardized {valid_count}/{len(df)} molecules.\")\n",
    "    return df\n",
    "\n",
    "# --- Process drugRepurposing_hub ---\n",
    "drugRepurposing_hub = process_dataframe_chemistry(\n",
    "    drugRepurposing_hub,\n",
    "    smiles_col='smiles',\n",
    "    new_inchikey_col='INCHIKEY-Canonical'\n",
    ")\n",
    "\n",
    "# --- Process drugbank_smiles ---\n",
    "drugbank_smiles = process_dataframe_chemistry(\n",
    "    drugbank_smiles,\n",
    "    smiles_col='Smiles',\n",
    "    new_inchikey_col='INCHIKEY-Canonical'\n",
    ")\n",
    "\n",
    "chebi = process_dataframe_chemistry(\n",
    "    chebi,\n",
    "    smiles_col='SMILES',\n",
    "    new_inchikey_col='INCHIKEY-Canonical'\n",
    ")\n",
    "Antibacterial= process_dataframe_chemistry(\n",
    "    Antibacterial,\n",
    "    smiles_col='Smile',\n",
    "    new_inchikey_col='INCHIKEY-Canonical'\n",
    ")\n",
    "# chembl= process_dataframe_chemistry(\n",
    "#     chembl,\n",
    "#     smiles_col='SMILES',\n",
    "#     new_inchikey_col='INCHIKEY-Canonical'\n",
    "# )   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c32171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standardize Column Names ---\n",
    "\n",
    "# 2. Antibacterial Library: Rename 'InChI Key' to 'INCHIKEY'\n",
    "# Antibacterial.rename(columns={'InChI Key': 'INCHIKEY'}, inplace=True)\n",
    "# print(f\"Antibacterial column names after rename: {list(Antibacterial.columns)}\")\n",
    "\n",
    "# --- Create a list of the DataFrames to iterate over for overlap analysis ---\n",
    "datasets = {\n",
    "    'ChEBI': chebi,\n",
    "    'chemdiv': Antibacterial,\n",
    "    'Drug Repurposing Hub': drugRepurposing_hub,\n",
    "    'DrugBank SMILES': drugbank_smiles\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# --- SECTION 1: Overlap with ChEMBL (Your original logic) ---\n",
    "# chembl_inchikeys = set(chembl['INCHIKEY'].dropna().str.strip())\n",
    "# N_chembl = len(chembl_inchikeys)\n",
    "\n",
    "# print(f\"\\nTotal unique InChIKeys in Filtered ChEMBL: {N_chembl}\")\n",
    "# print(\"\\n## ðŸ”¬ Overlap Analysis: Libraries vs. Filtered ChEMBL\")\n",
    "# print(f\"| {'Library':<25} | {'Shared Molecules':<18} | {'Jaccard Index (%)':<20} |\")\n",
    "# print(f\"|{'-'*26}|{'-'*19}|{'-'*22}|\")\n",
    "\n",
    "# # Store library sets in a dict for the next step\n",
    "library_sets = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    lib_keys = set(df['INCHIKEY-Canonical'].dropna().str.strip())\n",
    "    library_sets[name] = lib_keys\n",
    "    \n",
    "#     shared = lib_keys.intersection(chembl_inchikeys)\n",
    "#     union = lib_keys.union(chembl_inchikeys)\n",
    "#     jaccard = (len(shared) / len(union)) * 100 if union else 0\n",
    "    \n",
    "#     print(f\"| {name:<25} | {len(shared):<18} | {jaccard:.4f}% |\")\n",
    "\n",
    "# --- SECTION 2: Pairwise Library Overlap (New) ---\n",
    "print(\"\\n## ðŸ¤ Pairwise Library Overlap Analysis\")\n",
    "print(f\"| {'Library A':<20} | {'Library B':<20} | {'Shared':<10} | {'Jaccard Index (%)':<20} |\")\n",
    "print(f\"|{'-'*22}|{'-'*22}|{'-'*12}|{'-'*22}|\")\n",
    "\n",
    "# Get all unique pairs of libraries\n",
    "lib_names = list(library_sets.keys())\n",
    "for name_a, name_b in itertools.combinations(lib_names, 2):\n",
    "    set_a = library_sets[name_a]\n",
    "    set_b = library_sets[name_b]\n",
    "    \n",
    "    shared = set_a.intersection(set_b)\n",
    "    union = set_a.union(set_b)\n",
    "    jaccard = (len(shared) / len(union)) * 100 if union else 0\n",
    "    \n",
    "    print(f\"| {name_a:<20} | {name_b:<20} | {len(shared):<10} | {jaccard:.4f}% |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# 1. Initialize the Shared Matrix\n",
    "# (Assuming library_sets is defined in your environment)\n",
    "names = list(library_sets.keys())\n",
    "n = len(names)\n",
    "shared_matrix = pd.DataFrame(np.zeros((n, n), dtype=int), index=names, columns=names)\n",
    "\n",
    "for i, name_a in enumerate(names):\n",
    "    for j, name_b in enumerate(names):\n",
    "        count = len(library_sets[name_a].intersection(library_sets[name_b]))\n",
    "        shared_matrix.iloc[i, j] = count\n",
    "\n",
    "# 2. DEFINE YOUR THRESHOLDS\n",
    "thresholds = [0, 1, 10, 100, 1000, 5000, 10000]\n",
    "\n",
    "# 3. Choose colors for each bin\n",
    "colors = [\"#fffff0\", \"#FAD782\", \"#FAA08B\", \"#8DC7FA\", \"#AA96FA\", \"#50285A\", \"#50285A\"]\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "norm = mcolors.BoundaryNorm(thresholds, cmap.N, extend='max')\n",
    "\n",
    "# 4. Prepare Masks for Lower Triangle\n",
    "# np.triu returns the upper triangle of an array.\n",
    "# k=1 means we start masking 1 unit above the main diagonal.\n",
    "upper_tri_mask = np.triu(np.ones_like(shared_matrix, dtype=bool), k=1)\n",
    "diag_mask = np.eye(n, dtype=bool)\n",
    "\n",
    "# Combined mask for the colored overlap (Mask Upper + Mask Diagonal)\n",
    "off_diag_mask_to_hide = upper_tri_mask | diag_mask\n",
    "\n",
    "# Combined mask for the grey diagonal (Mask Upper + Mask Lower)\n",
    "# This leaves only the diagonal visible.\n",
    "diag_only_mask_to_hide = upper_tri_mask | ~diag_mask\n",
    "\n",
    "# 5. Create the Visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# First Layer: Plot the Shared Counts (Lower Triangle Only)\n",
    "ax = sns.heatmap(shared_matrix, \n",
    "                 mask=off_diag_mask_to_hide, \n",
    "                 annot=True, \n",
    "                 fmt=\"d\", \n",
    "                 cmap=cmap, \n",
    "                 norm=norm, \n",
    "                 annot_kws={\"size\": 14},\n",
    "                 cbar_kws={'label': 'Shared Molecules (Overlap Scale)'},\n",
    "                 linewidths=1,\n",
    "                 linecolor='white')\n",
    "\n",
    "# Second Layer: Plot the Diagonal (Grey)\n",
    "# We use the same 'ax' to overlay the diagonal on the same plot\n",
    "sns.heatmap(shared_matrix, \n",
    "            mask=diag_only_mask_to_hide, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            annot_kws={\"size\": 14},\n",
    "            cmap=mcolors.ListedColormap(['#d3d3d3']), # Light Grey for diagonal\n",
    "            cbar=False, \n",
    "            ax=ax)\n",
    "\n",
    "# Final Formatting\n",
    "plt.title(\"Chemical Overlap\", fontsize=16, pad=20)\n",
    "plt.xlabel(\"Library\", fontsize=12)\n",
    "plt.ylabel(\"Library\", fontsize=12)\n",
    "\n",
    "# Optional: Adjust layout to ensure no clipping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr =  df.corr()\n",
    "\n",
    "# Create a mask\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. SETUP: Prepare DataFrames and Descriptors ---\n",
    "\n",
    "# Dictionary of datasets and their SMILES/Molecule column names\n",
    "# Assuming 'ROMol' is the default column name from PandasTools.LoadSDF for SDF files\n",
    "datasets_info = {\n",
    "    'Filtered ChEMBL': {'df': chembl, 'smiles_col': 'SMILES', 'mol_col': 'Mol'},\n",
    "    'ChEBI': {'df': chebi, 'smiles_col': None, 'mol_col': 'ROMol'},\n",
    "    'Antibacterial': {'df': Antibacterial, 'smiles_col': None, 'mol_col': 'ROMol'},\n",
    "    'Drug Repurposing Hub': {'df': drugRepurposing_hub, 'smiles_col': 'smiles', 'mol_col': 'Mol'},\n",
    "    'DrugBank SMILES': {'df': drugbank_smiles, 'smiles_col': 'Smiles', 'mol_col': 'Mol'}\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def ensure_mol_column(df, smiles_col, mol_col):\n",
    "    \"\"\"Ensure a molecule object column exists for SMILES-based DataFrames.\"\"\"\n",
    "    if smiles_col and mol_col not in df.columns:\n",
    "        print(f\"Generating Mol objects for: {smiles_col}\")\n",
    "        df[mol_col] = df[smiles_col].apply(lambda x: Chem.MolFromSmiles(str(x)) if pd.notna(x) else None)\n",
    "    return df\n",
    "\n",
    "def calculate_descriptors(df, mol_col):\n",
    "    \"\"\"Calculates all required RDKit descriptors.\"\"\"\n",
    "    print(f\"Calculating descriptors based on column: {mol_col}\")\n",
    "    df['MW'] = df[mol_col].apply(lambda mol: Descriptors.MolWt(mol) if mol else None)\n",
    "    df['HeavyAtoms'] = df[mol_col].apply(lambda mol: Descriptors.HeavyAtomCount(mol) if mol else None)\n",
    "    df['NumRings'] = df[mol_col].apply(lambda mol: CalcNumRings(mol) if mol else None)\n",
    "    df['LogP'] = df[mol_col].apply(lambda mol: Descriptors.MolLogP(mol) if mol else None)\n",
    "    df['HBD'] = df[mol_col].apply(lambda mol: Descriptors.NumHDonors(mol) if mol else None)\n",
    "    df['HBA'] = df[mol_col].apply(lambda mol: Descriptors.NumHAcceptors(mol) if mol else None)\n",
    "    df['RotatableBonds'] = df[mol_col].apply(lambda mol: Descriptors.NumRotatableBonds(mol) if mol else None)\n",
    "    return df\n",
    "\n",
    "# --- 2. EXECUTION: Process DataFrames ---\n",
    "\n",
    "all_data_list = []\n",
    "\n",
    "for name, info in datasets_info.items():\n",
    "    df = info['df']\n",
    "    smiles_col = info['smiles_col']\n",
    "    mol_col = info['mol_col']\n",
    "\n",
    "    # 2.1 Ensure Mol column is present for SMILES-based files\n",
    "    df = ensure_mol_column(df, smiles_col, mol_col)\n",
    "\n",
    "    # 2.2 Calculate descriptors\n",
    "    df = calculate_descriptors(df, mol_col)\n",
    "\n",
    "    # 2.3 Create a subset and add a 'Library' identifier column\n",
    "    subset_cols = ['MW', 'HeavyAtoms', 'NumRings', 'LogP', 'HBD', 'HBA', 'RotatableBonds']\n",
    "    temp_df = df[subset_cols].copy()\n",
    "    temp_df['Library'] = name\n",
    "    all_data_list.append(temp_df)\n",
    "\n",
    "# Combine all data into one DataFrame for easy plotting\n",
    "plot_data = pd.concat(all_data_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd62252",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    'MW': 'Molecular Weight',\n",
    "    'LogP': 'LogP',\n",
    "    'HeavyAtoms': 'Heavy Atoms',\n",
    "    'NumRings': 'Number of Rings',\n",
    "    'HBD': 'HB Donors',\n",
    "    'HBA': 'HB Acceptors',\n",
    "    'RotatableBonds': 'Rotatable Bonds'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'plot_data' DataFrame is available from the previous run\n",
    "\n",
    "print(\"## ðŸ§¼ Final Data Cleaning on Plot Data\")\n",
    "\n",
    "# --- Cleaning the Library Column ---\n",
    "# Strip any leading/trailing whitespace from the Library column\n",
    "plot_data['Library'] = plot_data['Library'].astype(str).str.strip()\n",
    "\n",
    "# Check unique values after cleaning (to confirm the fix)\n",
    "print(\"Unique Libraries found after cleaning:\")\n",
    "print(plot_data['Library'].unique())\n",
    "\n",
    "\n",
    "# --- Re-Plotting (Using the corrected, robust code from last turn) ---\n",
    "\n",
    "# Define the properties to plot and their display names\n",
    "properties = {\n",
    "    'MW': 'Molecular Weight',\n",
    "    'LogP': 'LogP',\n",
    "    'HeavyAtoms': 'Heavy Atoms',\n",
    "    'NumRings': 'Number of Rings',\n",
    "    'HBD': 'HB Donors',\n",
    "    'HBA': 'HB Acceptors',\n",
    "    'RotatableBonds': 'Rotatable Bonds'\n",
    "}\n",
    "\n",
    "n_plots = len(properties)\n",
    "n_cols = 2\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols \n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get the list of unique libraries for the legend title\n",
    "unique_libraries = plot_data['Library'].unique()\n",
    "\n",
    "# Use a color palette distinct enough for 5 libraries\n",
    "palette = sns.color_palette(\"Set2\", len(unique_libraries))\n",
    "color_map = dict(zip(unique_libraries, palette))\n",
    "\n",
    "\n",
    "for i, (col, title) in enumerate(properties.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot the density using the cleaned data\n",
    "    sns.kdeplot(\n",
    "        data=plot_data,\n",
    "        x=col,\n",
    "        hue='Library',\n",
    "        fill=False,\n",
    "        alpha=0.5,\n",
    "        linewidth=1.5,\n",
    "        palette=color_map, \n",
    "        ax=ax,\n",
    "        legend=True \n",
    "    )\n",
    "    \n",
    "    # Add titles and labels\n",
    "    ax.set_title(f'Distribution of {title}', fontsize=16)\n",
    "    ax.set_xlabel(title, fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Turn off any extra empty subplots\n",
    "for i in range(n_plots, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Force display of the plot in the notebook\n",
    "plt.show() \n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Library_Property_Overlap_Cleaned.png')\n",
    "print(\"\\n[Image saved as 'Library_Property_Overlap_Cleaned.png']\")\n",
    "print(\"All distribution plots should now be visible with 5 densities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d512c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'plot_data' DataFrame is available, cleaned, and contains the descriptor columns\n",
    "\n",
    "print(\"## ðŸ“Š Step 8: Plotting with Zoomed-In Y-Axis for Small Libraries\")\n",
    "\n",
    "# Define the properties to plot\n",
    "properties = {\n",
    "    'MW': 'Molecular Weight',\n",
    "    'LogP': 'LogP',\n",
    "    'HeavyAtoms': 'Heavy Atoms',\n",
    "    'NumRings': 'Number of Rings',\n",
    "    'HBD': 'HB Donors',\n",
    "    'HBA': 'HB Acceptors',\n",
    "    'RotatableBonds': 'Rotatable Bonds'\n",
    "}\n",
    "\n",
    "n_plots = len(properties)\n",
    "n_cols = 2\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols \n",
    "\n",
    "# Get unique libraries and color map\n",
    "unique_libraries = plot_data['Library'].unique()\n",
    "palette = sns.color_palette(\"Set2\", len(unique_libraries))\n",
    "color_map = dict(zip(unique_libraries, palette))\n",
    "\n",
    "# --- Plot Set 1: Full Range (Reference) ---\n",
    "# This is mainly to see the ChEMBL peak.\n",
    "\n",
    "fig1, axes1 = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows)) \n",
    "axes1 = axes1.flatten()\n",
    "\n",
    "for i, (col, title) in enumerate(properties.items()):\n",
    "    ax = axes1[i]\n",
    "    sns.kdeplot(\n",
    "        data=plot_data, x=col, hue='Library', fill=False, linewidth=2.0, \n",
    "        palette=color_map, ax=ax, legend=True \n",
    "    )\n",
    "    ax.set_title(f'Full Range: Distribution of {title}', fontsize=16)\n",
    "    ax.set_xlabel(title, fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for i in range(n_plots, len(axes1)):\n",
    "    fig1.delaxes(axes1[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "plt.savefig('Property_Overlap_FullRange.png')\n",
    "print(\"\\n[Image saved as 'Property_Overlap_FullRange.png']\")\n",
    "\n",
    "\n",
    "# --- Plot Set 2: Zoomed-In Y-Axis (Focus on Small Libraries) ---\n",
    "# We'll use a maximum Y limit of 0.0002 (or 0.0005) to reveal the small libraries.\n",
    "# You may need to adjust Y_LIMIT based on your exact data.\n",
    "\n",
    "Y_LIMIT = 0.0015 \n",
    "\n",
    "fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows)) \n",
    "axes2 = axes2.flatten()\n",
    "\n",
    "for i, (col, title) in enumerate(properties.items()):\n",
    "    ax = axes2[i]\n",
    "    sns.kdeplot(\n",
    "        data=plot_data, x=col, hue='Library', fill=False, linewidth=2.0, \n",
    "        palette=color_map, ax=ax, legend=True \n",
    "    )\n",
    "    \n",
    "    # --- KEY CHANGE: Set the Y-axis limit ---\n",
    "    ax.set_ylim(0, Y_LIMIT)\n",
    "    \n",
    "    ax.set_title(f'Zoomed (Y-Max {Y_LIMIT}): Distribution of {title}', fontsize=16)\n",
    "    ax.set_xlabel(title, fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "for i in range(n_plots, len(axes2)):\n",
    "    fig2.delaxes(axes2[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "plt.savefig('Property_Overlap_Zoomed.png')\n",
    "print(\"\\n[Image saved as 'Property_Overlap_Zoomed.png']\")\n",
    "print(\"Successfully generated two sets of plots: one full range and one zoomed into the low-density area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ec591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolToSmiles\n",
    "\n",
    "# --- 1. Setup DataFrames and Column Mapping ---\n",
    "\n",
    "# Define the source DataFrames and their respective SMILES/Mol column names\n",
    "all_source_data = [\n",
    "    {'df': chembl,                 'inchikey_col': 'INCHIKEY', 'smiles_col': 'SMILES', 'mol_col': 'Mol', 'name': 'Filtered ChEMBL'},\n",
    "    {'df': chebi,                  'inchikey_col': 'INCHIKEY', 'smiles_col': None,     'mol_col': 'ROMol', 'name': 'ChEBI'},\n",
    "    {'df': Antibacterial,          'inchikey_col': 'INCHIKEY', 'smiles_col': None,     'mol_col': 'ROMol', 'name': 'Antibacterial'},\n",
    "    {'df': drugRepurposing_hub,    'inchikey_col': 'INCHIKEY', 'smiles_col': 'smiles', 'mol_col': 'Mol', 'name': 'Drug Repurposing Hub'},\n",
    "    {'df': drugbank_smiles,        'inchikey_col': 'INCHIKEY', 'smiles_col': 'Smiles', 'mol_col': 'Mol', 'name': 'DrugBank SMILES'}\n",
    "]\n",
    "\n",
    "# --- 2. Helper Function to get SMILES ---\n",
    "\n",
    "def get_canonical_smiles(row, smiles_col, mol_col):\n",
    "    \"\"\"\n",
    "    Returns the canonical SMILES string from either a SMILES column or a Mol column.\n",
    "    Handles potential failure if both are None or invalid.\n",
    "    \"\"\"\n",
    "    mol = None\n",
    "    if smiles_col and pd.notna(row[smiles_col]):\n",
    "        # Try converting from SMILES string (CSV sources)\n",
    "        mol = Chem.MolFromSmiles(str(row[smiles_col]))\n",
    "    elif mol_col in row and row[mol_col] is not None:\n",
    "        # Use the existing RDKit Mol object (SDF sources)\n",
    "        mol = row[mol_col]\n",
    "\n",
    "    if mol:\n",
    "        # Convert to canonical SMILES\n",
    "        try:\n",
    "            return MolToSmiles(mol, isomericSmiles=True, canonical=True)\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# --- 3. Build the Master INCHIKEY-SMILES Lookup Table ---\n",
    "\n",
    "master_lookup_list = []\n",
    "\n",
    "print(\"## ðŸ” Building INCHIKEY and Canonical SMILES Lookup Table\")\n",
    "\n",
    "for data in all_source_data:\n",
    "    df = data['df'].copy()\n",
    "    inchikey_col = data['inchikey_col']\n",
    "    smiles_col = data['smiles_col']\n",
    "    mol_col = data['mol_col']\n",
    "    \n",
    "    # Generate canonical SMILES for every row\n",
    "    df['Canonical_SMILES'] = df.apply(\n",
    "        lambda row: get_canonical_smiles(row, smiles_col, mol_col), axis=1\n",
    "    )\n",
    "    \n",
    "    # Keep only the essential columns for lookup\n",
    "    lookup_subset = df[[inchikey_col, 'Canonical_SMILES']].copy()\n",
    "    lookup_subset.rename(columns={inchikey_col: 'INCHIKEY'}, inplace=True)\n",
    "    \n",
    "    # Clean and deduplicate the lookup set for this library\n",
    "    lookup_subset.dropna(subset=['INCHIKEY', 'Canonical_SMILES'], inplace=True)\n",
    "    lookup_subset.drop_duplicates(subset=['INCHIKEY'], keep='first', inplace=True)\n",
    "    \n",
    "    master_lookup_list.append(lookup_subset)\n",
    "\n",
    "# Combine all lookups and deduplicate the FINAL list by INCHIKEY\n",
    "smiles_lookup = pd.concat(master_lookup_list, ignore_index=True)\n",
    "smiles_lookup.drop_duplicates(subset=['INCHIKEY'], keep='first', inplace=True)\n",
    "\n",
    "print(f\"Total unique (INCHIKEY, SMILES) pairs created: {len(smiles_lookup)}\")\n",
    "\n",
    "\n",
    "# --- 4. Merge the Lookup Table with the Integrated Dataset ---\n",
    "\n",
    "# master_dataset_inchikeys is the integrated list from Step 6 (INCHIKEY, Original_Library)\n",
    "\n",
    "master_dataset = pd.merge(\n",
    "    master_dataset_inchikeys,\n",
    "    smiles_lookup,\n",
    "    on='INCHIKEY',\n",
    "    how='left' # Keep all entries from our integrated list\n",
    ")\n",
    "\n",
    "# Final cleanup: drop any rows that somehow lost their SMILES during the merge \n",
    "# (Should be few, but good practice)\n",
    "master_dataset.dropna(subset=['Canonical_SMILES'], inplace=True)\n",
    "\n",
    "# Rename for clarity\n",
    "master_dataset.rename(columns={'Canonical_SMILES': 'SMILES'}, inplace=True)\n",
    "\n",
    "print(f\"\\n--- Final Master Dataset Creation Complete ---\")\n",
    "print(f\"Final Master Dataset Size (with SMILES): {len(master_dataset)}\")\n",
    "print(\"Final Master Dataset Head:\")\n",
    "print(master_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming the 'master_dataset' DataFrame is available from the previous step 9\n",
    "\n",
    "# --- 1. Prepare the DataFrame for Saving ---\n",
    "# Select only the 'SMILES' column\n",
    "smiles_only_df = master_dataset[['SMILES']].copy()\n",
    "\n",
    "# --- 2. Define the File Name ---\n",
    "output_filename = 'master_dataset_smiles.csv'\n",
    "\n",
    "# --- 3. Save to CSV ---\n",
    "smiles_only_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\n## âœ… Integration Complete: Master SMILES Saved\")\n",
    "print(f\"The final list of unique SMILES has been successfully saved to: {output_filename}\")\n",
    "print(f\"File contents verification (first 5 lines):\")\n",
    "\n",
    "# Verification: Print the head of the saved file to confirm format\n",
    "with open(output_filename, 'r') as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline().strip())\n",
    "\n",
    "print(f\"\\nTotal SMILES saved: {len(smiles_only_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5bb707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778601e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
